{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ddf95d-cd6c-4484-89be-5787453db4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "# import yaml\n",
    "import datetime\n",
    "from itertools import combinations\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Data Analysis\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Modeling\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder,RobustScaler,MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge,Lasso,ElasticNet,LinearRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Neural Network\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(1)\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd64732f-7d21-4df6-a842-e214aef57c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor(object):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,target,stage):\n",
    "        try:\n",
    "            assert stage in ['dev','test','prod']\n",
    "        except:\n",
    "            raise Exception('Unknown stage')\n",
    "        self.stage = stage\n",
    "        \n",
    "        cwd = os.getcwd()\n",
    "        kaggle = os.path.join(cwd,'kaggle')\n",
    "        \n",
    "        self.target = target\n",
    "        self.train_df = pd.read_csv(os.path.join(kaggle,'train.csv'),header=0,index_col=0)\n",
    "        self.test_df = pd.read_csv(os.path.join(kaggle,'test.csv'),header=0,index_col=0)\n",
    "        \n",
    "        # with open(os.path.join(os.getcwd(),'features.yml'),'r') as file:\n",
    "        #     self.features_yml = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        self.features = None\n",
    "        self._get_features()\n",
    "        \n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.idx_train = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "        self.idx_test = None\n",
    "        \n",
    "        self.train_dummies = None\n",
    "        self.test_dummies = None\n",
    "        self.dummies = None\n",
    "        \n",
    "        self.train_encoded = None\n",
    "        self.test_encoded = None\n",
    "        \n",
    "        self.scaler = None\n",
    "        self.train_standardized = None\n",
    "        self.test_standardized = None\n",
    "        \n",
    "        self.train_combined = None\n",
    "        self.test_combined = None\n",
    "        \n",
    "        self.selector = None\n",
    "        self.estimator= None\n",
    "        self.selected_features = None\n",
    "        self.train_selected = None\n",
    "        self.test_selected = None\n",
    "        \n",
    "        self.X_fit = None\n",
    "        self.y_fit = None\n",
    "        self.X_score = None\n",
    "        self.y_score = None\n",
    "        self.X_pred = None\n",
    "        self.y_pred = None\n",
    "        \n",
    "                    \n",
    "    def _get_features(self,refresh=False):\n",
    "        # features = {'all':[]}\n",
    "        # for feature,info in self.features_yml.items():\n",
    "        #     features['all'].append(feature)\n",
    "        #     if not features.get(info['dtype'],None):\n",
    "        #         features[info['dtype']] = []\n",
    "        #     features[info['dtype']].append(feature)\n",
    "        # self.features = features\n",
    "        drop = [\n",
    "            # 'Alley','LandContour','LandSlope',\n",
    "            # 'Condition2','MSSubClass','HouseStyle',\n",
    "            # 'YearRemodAdd','RoofStyle','RoofMatl',\n",
    "            # 'Exterior1st','Exterior2nd','MasVnrType',\n",
    "            # 'MasVnrArea','BsmtExposure','BsmtFinType1',\n",
    "            # 'BsmtFinSF1','BsmtFinType2','BsmtFinSF2',\n",
    "            # 'BsmtUnfSF','TotRmsAbvGrd','Fireplaces',\n",
    "            # 'FireplaceQu','GarageType','GarageYrBlt',\n",
    "        ]\n",
    "        \n",
    "        features = {\n",
    "            'all':[],\n",
    "            'target':['Target'],\n",
    "            'cat':[],\n",
    "            'num':[],\n",
    "            'encoded':[],\n",
    "            'other':[]\n",
    "        }\n",
    "        if refresh:\n",
    "            df = self.X_train\n",
    "        else:\n",
    "            df = self.train_df\n",
    "        \n",
    "        for c in df.columns:\n",
    "            if c not in drop:\n",
    "                features['all'].append(c)\n",
    "\n",
    "                if c==self.target:\n",
    "                    None # features['target'].append(c)\n",
    "                elif len(df[c].unique()) > 30:\n",
    "                    features['num'].append(c)\n",
    "                elif type(df[c].dropna().values[0])==str:\n",
    "                    features['cat'].append(c)\n",
    "                elif type(df[c].dropna().values[0])==np.int64:\n",
    "                    features['encoded'].append(c)\n",
    "                else:\n",
    "                    features['other'].append(c)\n",
    "        \n",
    "        if len(features['other']) > 0:\n",
    "            raise Exception('Uncategorized features')\n",
    "        \n",
    "        self.features = features\n",
    "    \n",
    "    def clean(self):\n",
    "        df = self.train_df[self.features['all']].rename({self.target:'Target'},axis=1)\n",
    "        df = df.dropna(axis=1,thresh=(df.shape[0]*0.6)).fillna('0')\n",
    "        df.index = df.index.astype(str)\n",
    "        \n",
    "        for dtype,fields in self.features.items():\n",
    "            for field in fields:\n",
    "                if field not in df.columns:\n",
    "                    fields.remove(field)\n",
    "        \n",
    "        self.y_train = df.Target\n",
    "        self.X_train = df.drop(self.features['target'],axis=1)\n",
    "        self.idx_train = df.index\n",
    "                \n",
    "        df = self.test_df[self.features['all']].fillna('0')\n",
    "        df.index = df.index.astype(str)\n",
    "        self.X_test = df\n",
    "        self.idx_test = self.X_test.index\n",
    "        \n",
    "        self._get_features(refresh=True)\n",
    "        \n",
    "    def dummy(self):\n",
    "        self.train_dummies = pd.get_dummies(self.X_train[self.features['cat']])\n",
    "        self.test_dummies = pd.get_dummies(self.X_test[self.features['cat']])\n",
    "        self.dummies = list(set(list(self.train_dummies.columns)+list(self.test_dummies.columns)))\n",
    "        \n",
    "        for column in self.dummies:\n",
    "            if column not in self.train_dummies:\n",
    "                self.train_dummies[column] = 0\n",
    "            if column not in self.test_dummies:\n",
    "                self.test_dummies[column] = 0\n",
    "        \n",
    "        self.train_dummies = self.train_dummies[self.dummies]\n",
    "        self.test_dummies = self.test_dummies[self.dummies]\n",
    "    \n",
    "    def encode(self):\n",
    "        train = pd.DataFrame(index=self.idx_train)\n",
    "        test = pd.DataFrame(index=self.idx_test)\n",
    "        for c in self.features['cat']:\n",
    "            encoder = LabelEncoder()\n",
    "            encoder.fit(self.X_train[c].values)\n",
    "            train[c] = encoder.transform(self.X_train[c].values)\n",
    "            test[c] = encoder.transform(self.X_test[c].values)\n",
    "        self.train_encoded = train\n",
    "        self.test_encoded = test\n",
    "    \n",
    "    def standardize(self,scaler):\n",
    "        if scaler == 'standard':\n",
    "            self.scaler = StandardScaler()\n",
    "        elif scaler == 'robust': \n",
    "            self.scaler = RobustScaler()\n",
    "        elif scaler == 'minmax':\n",
    "            self.scaler = MinMaxScaler()\n",
    "        else:\n",
    "            raise Exception('Unknown scaler option')\n",
    "        self.scaler.fit(self.X_train[self.features['num']+self.features['encoded']])\n",
    "        self.scaler.fit(self.X_test[self.features['num']+self.features['encoded']])\n",
    "        \n",
    "        self.train_standardized = pd.DataFrame(\n",
    "            self.scaler.transform(self.X_train[self.features['num']+self.features['encoded']])\n",
    "            ,columns=self.features['num']+self.features['encoded'],index=self.idx_train\n",
    "        )\n",
    "        self.test_standardized = pd.DataFrame(\n",
    "            self.scaler.transform(self.X_test[self.features['num']+self.features['encoded']])\n",
    "            ,columns=self.features['num']+self.features['encoded'],index=self.idx_test\n",
    "        )\n",
    "    \n",
    "    def combine(self):\n",
    "        self.train_combined = self.train_dummies.join(self.train_standardized,how='inner')\n",
    "        self.test_combined = self.test_dummies.join(self.test_standardized,how='inner')\n",
    "    \n",
    "    def select(self,num_columns=120):\n",
    "        self.estimator = SVR(kernel='linear')\n",
    "        self.selector = RFE(self.estimator, n_features_to_select=num_columns, step=1)\n",
    "        self.selector.fit(self.train_combined,self.y_train)\n",
    "        self.selected_features = self.selector.get_feature_names_out(self.selector.feature_names_in_)\n",
    "        \n",
    "        self.train_selected = self.train_combined[self.selected_features]\n",
    "        self.test_selected = self.test_combined[self.selected_features]\n",
    "        \n",
    "    def split(self):\n",
    "        (self.X_fit,self.X_score,\n",
    "        self.y_fit,self.y_score) = train_test_split(\n",
    "            self.train_selected,self.y_train,\n",
    "            test_size=0.2,random_state=42\n",
    "        )\n",
    "        self.X_pred = self.test_selected\n",
    "    \n",
    "    def audit(self):\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d1d33d-c335-4b90-aa3b-3221a8c5c3a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a461e6fd-4b48-457d-89b2-14819c361f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78f20a9-3838-4ced-98c8-ce6f78bd4b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34069631-cdfc-41fd-ad07-606f0015865f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc37eb3-c041-47d3-8245-b5c8881bc8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c028232-a1cc-49e1-ad61-faac58d09e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b99918d-8063-40f2-90df-c74a9d12b90b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3b3268-afbe-4c74-8cbb-edb2a2738223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d51897-ec8e-4306-bb19-9794efc59599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b921b-6425-4e7a-bc31-94ffb3bdf572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f464515-81c1-4878-9c41-13ecf5950107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f3e1c6-6f99-4529-ae79-f4bd996f5cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b69e0c9-6716-4ef4-ace8-2f0f838097f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c014a7ab-f75b-401a-a23c-2cf947b16b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2351be-79fa-456c-b942-4716bffc7831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2c8fd-830a-4911-8461-adcff68f2bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76150d60-1dce-4975-b4e8-a83274185c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad1b36-dd1e-46d0-8135-012e0f477d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca0a67-cfc2-45e6-b378-b375fb85d826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbe2f87-bfb7-4a30-b14d-37e5ea3667a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4172bf7b-dd04-47a2-8df1-634cd77f46de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ec13eb-b84a-405b-889c-d3e260f88b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1080f79f-a55a-4371-97e5-85c30463ab43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35dc1a8-31e0-4991-adb4-4076977a5c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c311c-1abb-473d-9dd8-48034454b2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaa99c4-ed01-48c6-b12e-dab5d059db71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
